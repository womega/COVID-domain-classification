{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluates a decision tree model on the imbalanced dataset\n",
    "from numpy import mean\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "import pandas as pd\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from collections import Counter\n",
    "from sklearn.metrics import confusion_matrix, make_scorer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('final_dataset_new.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(['Domain', 'Label', 'Subdomain levels'], axis=1)\n",
    "y = data['Label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model\n",
    "model = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 37610, 1: 3904})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'''When callable, function taking y and returns a dict.\n",
    "The keys correspond to the targeted classes.\n",
    "The values correspond to the desired number of samples for each class.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def call(y):\n",
    "    a = {}\n",
    "    ratio = int(4 * Counter(y)[1])\n",
    "    a[0] = ratio\n",
    "    a[1] = Counter(y)[1]\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 338 ms, sys: 53.3 ms, total: 391 ms\n",
      "Wall time: 641 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from imblearn.under_sampling import NearMiss\n",
    "\n",
    "X_nm, y_nm = NearMiss(sampling_strategy=0.25, n_neighbors=3).fit_sample(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 36min 25s, sys: 16.1 s, total: 36min 41s\n",
      "Wall time: 37min 24s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from imblearn.under_sampling import CondensedNearestNeighbour\n",
    "\n",
    "X_cnn, y_cnn = CondensedNearestNeighbour(n_neighbors=3).fit_sample(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 941 ms, sys: 20.4 ms, total: 961 ms\n",
      "Wall time: 969 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from imblearn.under_sampling import EditedNearestNeighbours\n",
    "\n",
    "X_enn, y_enn = EditedNearestNeighbours(n_neighbors=3).fit_sample(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 887 ms, sys: 9.69 ms, total: 897 ms\n",
      "Wall time: 902 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from imblearn.under_sampling import TomekLinks\n",
    "\n",
    "X_tl, y_tl = TomekLinks().fit_sample(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NM Counter({0: 15616, 1: 3904})\n",
      "CNN Counter({1: 3904, 0: 2065})\n",
      "ENN Counter({0: 36255, 1: 3904})\n",
      "TL Counter({0: 37348, 1: 3904})\n"
     ]
    }
   ],
   "source": [
    "print(\"NM\", Counter(y_nm))\n",
    "print(\"CNN\", Counter(y_cnn))\n",
    "print(\"ENN\", Counter(y_enn))\n",
    "print(\"TL\", Counter(y_tl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def g_mean(y_true, y_pred): \n",
    "    tn = confusion_matrix(y_true, y_pred)[0, 0]\n",
    "    fp = confusion_matrix(y_true, y_pred)[0, 1]\n",
    "    tp = confusion_matrix(y_true, y_pred)[1, 1]\n",
    "    fn = confusion_matrix(y_true, y_pred)[1, 0]\n",
    "    neg = tn + fp\n",
    "    pos = tp + fn\n",
    "    specificity = tn/neg\n",
    "    sensitivity = tp/pos\n",
    "    gmean = math.sqrt(specificity*sensitivity)\n",
    "    return gmean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = RepeatedStratifiedKFold(n_splits=10, random_state=42)\n",
    "# evaluate model\n",
    "scores_nm = cross_val_score(model, X_nm, y_nm, scoring='roc_auc', cv=cv, n_jobs=-1)\n",
    "scores_cnn = cross_val_score(model, X_cnn, y_cnn, scoring='roc_auc', cv=cv, n_jobs=-1)\n",
    "scores_enn = cross_val_score(model, X_enn, y_enn, scoring='roc_auc', cv=cv, n_jobs=-1)\n",
    "scores_tl = cross_val_score(model, X_tl, y_tl, scoring='roc_auc', cv=cv, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean ROC AUC NM: 0.934\n",
      "Mean ROC AUC CNN: 0.837\n",
      "Mean ROC AUC ENN: 0.957\n",
      "Mean ROC AUC TL: 0.937\n"
     ]
    }
   ],
   "source": [
    "# summarize performance\n",
    "print('Mean ROC AUC NM: %.3f' % mean(scores_nm))\n",
    "print('Mean ROC AUC CNN: %.3f' % mean(scores_cnn))\n",
    "print('Mean ROC AUC ENN: %.3f' % mean(scores_enn))\n",
    "print('Mean ROC AUC TL: %.3f' % mean(scores_tl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(y_nm)[0]/len(y_nm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.34595409616351147"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(y_cnn)[0]/len(y_cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9027864239647402"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(y_enn)[0]/len(y_enn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9053621642587026"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(y_tl)[0]/len(y_tl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
